---
title: "Antelope Project Analysis"
author: "Andrea Stocco"
date: "October 31, 2019"
output: 
  rmarkdown::html_document:
    theme: cosmo
---

```{r setup, include=FALSE, warning=FALSE}
library(tidyverse)
library(kableExtra)
library(xtable)
library(data.table)
library(ggplot2)
library(ggthemes)
library(ggExtra)
library(colorspace)
library(RColorBrewer)
library(gridExtra)
library(ggdendro)
source("../../QEEG_Emotiv_Analysis_Rscript.R")
knitr::opts_chunk$set(echo = TRUE)
```

# Analyze the data

```{r}
process_raw = F
if (process_raw) {
  for (sub in dir(grep("A[1-9]", dir()))) {
    setwd(sub)
    analyze.logfile(sub, "closed")
    setwd("..")
  }
}
```

# Demographics and Behavioral Data


First, let's load the data and transform it into a Wide format table

```{r}
behav <- read_tsv("../../behav_data.txt", col_types=cols())

behav$material[behav$material=="Swahili"] <- "Vocabulary"
behav$material[behav$material=="US Maps"] <- "Maps"

behav <- behav %>% rename(Gender = gender, Age = age)

wbehav <- behav %>% pivot_wider(values_from = alpha,
                                id_cols = c(Subject, Gender, Age),
                                names_from = material)


```

At this point, we can look at the participant demographocs

```{r}
ggplot(data=wbehav, aes(x=Age, col=Gender)) +
  geom_histogram(aes(col="white", fill=Gender), colour="white", alpha=0.5, position="identity", binwidth = 1) +
  #geom_density(aes(fill=Gender), colour="black", position="dodge", bw=1,  alpha=0.5) +
  scale_color_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1") +
  ggtitle("Age Distribution by Gender")
  #geom_vline(aes(xintercept=grp.mean), linetype="dashed") +
  theme_pander()
```

## Values of Alpha for the two tasks

We can now examine the distribution and correlation of Alpha values for Vocab and Maps: 

```{r}

mu <- behav %>% group_by(material) %>% summarize(alpha=mean(alpha))

p1 <- ggplot(behav, aes(x=alpha, fill=material)) +
  geom_histogram(col="white", binwidth = 0.025, alpha=0.5, position="identity") +
  #geom_density(aes(fill=material), colour="white", position="dodge", alpha=0.5, bw=0.025) +
  scale_color_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1") +
#  geom_vline(aes(fun.data=mean_se, xintercept=material), linetype="dashed") +
  geom_vline(data=mu, aes(xintercept=alpha, color=material),
             linetype="dashed") +
  xlab(expression(paste("Estimated value of ", alpha))) +
  theme_pander() +
  ylab("Count") +
  ggtitle("(A) Distribution By Materials") +
  theme(legend.position = c(0.2, 0.8)) +
  theme(plot.title = element_text(hjust = 0.5))

p2 <- ggplot(wbehav, aes(x=Vocabulary, y=Maps)) +
  geom_point(size=4, alpha=0.5, col="black") + #col=K[7]) +
  geom_smooth(method = "lm", formula = y ~ x, col="red", fill="red", fullrange = T, lwd=2) +
  theme_pander() +
  #stat_density_2d(col="red", alpha=0.2) +
  scale_x_continuous() + 
  scale_y_continuous() + 
  ggtitle("(B) Correlation Across Materials") +
  xlab(expression(paste(alpha, " Vocabulary"))) +
  ylab(expression(paste(alpha, " Maps"))) +
  geom_rug(col="black", lwd=1, alpha=.5) +
  annotate("segment", x=0.1, y=0.1, xend=0.5, 
           yend=0.5, col="grey", lwd=1, lty=2) +
  theme(plot.title = element_text(hjust = 0.5))
  

grid.arrange(p1, p2, ncol=2)
```

```{r fig.width=5, fig.height=5 }
p3 <- ggplot(wbehav, aes(x=Vocabulary, y=Maps)) +
  geom_point(size=4, alpha=0.5, col="black") + #col=K[7]) +
  geom_smooth(method = "lm", formula = y ~ x, col="red", fill="red", fullrange = T, lwd=2) +
  theme_pander() +
  scale_x_continuous() + 
  scale_y_continuous() + 
  coord_fixed() +
  ggtitle("Correlation of Alpha Parameters\nAcross Materials") +
  xlab(expression(paste(alpha, " Vocabulary"))) +
  ylab(expression(paste(alpha, " Maps"))) +
  annotate("segment", x=0.1, y=0.1, xend=0.5, 
           yend=0.5, col="grey", lwd=1, lty=2) +
  annotate("text", label = paste("R =", round(cor(wbehav$Vocabulary,
                                                  wbehav$Maps),
                                              2)), 
                                 x=0.2, y=0.45, col="red") +
  
  theme(plot.title = element_text(hjust = 0.5))

ggMarginal(p3, col="white", fill="black", alpha=0.5,
           type="hist", bins=13)
```

And here is a summary of the data:

```{r}
summary(wbehav) %>%
  kable(digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

# Load the spectra

```{r}
spectra <- NULL
for (sub in dir()[grep("A[1-9]", dir())]) {
  table <- read_tsv(paste(sub, "/", sub, "_closed_spectra.txt", sep=""),
                    col_types = cols())
  if (is.null(spectra)) {
    spectra <- table
  } else {
    spectra <- spectra %>% bind_rows(table)
  }
}
```


# EEG Data Analysis

Here we begin looking at the EEG data analysis

## Average spectrum

First, let's examine the spectrograms for each channel to make sure it looks normal and the IAF (individual alpha frequency) is reasonable, i.e., the same for each channel and roughly in the middle of the band definition

```{r fig.width=6, fig.height=6}
lspectra <- pivot_longer(spectra, cols=names(spectra)[3:130], names_to="Freq")

lspectra <- lspectra %>% rename(Power = value)
#lspectra <- lspectra %>% mutate(Power = exp(Power))
lspectra$Frequency <- as.numeric(substr(lspectra$Freq, 0, str_length(lspectra$Freq) -2))
lspectra <- lspectra %>% add_column(Band="Delta", BandMin=0, BandMax=4) 
lspectra$Band[lspectra$Frequency <= 40] <- "Gamma"
lspectra$Band[lspectra$Frequency < 30] <- "High Beta"
lspectra$Band[lspectra$Frequency < 18] <- "Upper Beta"
lspectra$Band[lspectra$Frequency < 15] <- "Low Beta"
lspectra$Band[lspectra$Frequency < 13] <- "Alpha"
lspectra$Band[lspectra$Frequency < 8] <- "Theta"
lspectra$Band[lspectra$Frequency < 4] <- "Delta"

lspectra$BandMin[lspectra$Frequency <= 40] <- 30
lspectra$BandMin[lspectra$Frequency < 30] <- 18
lspectra$BandMin[lspectra$Frequency < 18] <- 13 #15
lspectra$BandMin[lspectra$Frequency < 15] <- 13
lspectra$BandMin[lspectra$Frequency < 13] <- 8
lspectra$BandMin[lspectra$Frequency < 8] <- 4
lspectra$BandMin[lspectra$Frequency < 4] <- 0

lspectra$BandMax[lspectra$Frequency <= 40] <- 40
lspectra$BandMax[lspectra$Frequency < 30] <- 30
lspectra$BandMax[lspectra$Frequency < 18] <- 18
lspectra$BandMax[lspectra$Frequency < 15] <- 15
lspectra$BandMax[lspectra$Frequency < 13] <- 13
lspectra$BandMax[lspectra$Frequency < 8] <- 8
lspectra$BandMax[lspectra$Frequency < 4] <- 4

lspectra$Band <- factor(lspectra$Band, 
                        levels = c("Delta", "Theta", "Alpha", 
                                   "Low Beta", "Upper Beta",
                                   "High Beta", "Gamma"))

```

Now, we remove the three participants for which we have poor quality data 

```{r}
lspectra <- lspectra %>%
  filter(Subject %in% behav$Subject)
```

Now, we can visualize the power spectra

```{r}
gd <- lspectra %>% 
        group_by(Band) %>% 
        summarise(
          Min = mean(BandMin),
          Max = mean(BandMax),
          Power =mean(Power),
          Frequency = mean(BandMin)
          #Channel=
        )

ggplot(data=lspectra, aes(x=Frequency, y=Power, Channel)) +
  geom_rect(data = gd, aes(xmin=Min, xmax=Max, fill=Band),  ymin=0, ymax=Inf, colour=NA, alpha=0.5) +
  stat_summary(#aes(fill=Channel), 
               fun.data=mean_sdl, 
               geom="ribbon", colour="white", alpha=0.4) +
  stat_summary(fun.y=mean, geom="line", lwd=1) +
  facet_wrap(~ Channel, ncol=4) +
  scale_alpha_manual(values = seq(0.1, 0.9, 0.1)) +
  ggtitle("Power Spectrum Across Channels") +
  ylab("Log Power") + 
  xlab("Frequency (Hz)") + 
  theme_pander() +
  coord_cartesian(xlim=c(1,40), ylim=c(5, 17)) + #ylim=c(5,17)) +
  scale_fill_brewer(palette = "Set3") +
  theme(plot.title = element_text(hjust = 0.5))


```

Now, let's create a mean spectrogram with annotations that mark the frequency bands

```{r}

K = brewer.pal(7, "Set3")

alspectra <- aggregate(lspectra[c("Power")],
                       list(Subject=lspectra$Subject, 
                            Frequency=lspectra$Frequency, 
                            Band=lspectra$Band), 
                       mean)

ggplot(data=alspectra, aes(x=Frequency, y=Power, col=Power)) +
  annotate("rect", xmin = 0, xmax = 4, ymin = 0, ymax = Inf, 
           alpha = 0.5, fill=K[1]) +
  annotate("rect", xmin = 4, xmax = 8, ymin = 0, ymax = Inf, 
           alpha = 0.5, fill=K[2]) +
  annotate("rect", xmin = 8, xmax = 13, ymin = 0, ymax = Inf, 
           alpha = 0.5, fill=K[3]) +      
  annotate("rect", xmin = 13, xmax = 15, ymin = 0, ymax = Inf, 
           alpha = 0.5, fill=K[4]) +
  annotate("rect", xmin = 15, xmax = 18, ymin = 0, ymax = Inf, 
           alpha = 0.5, fill = K[5]) +
  annotate("rect", xmin = 18, xmax = 30, ymin = 0, ymax = Inf, 
           alpha = 0.5, fill=K[6]) +
  annotate("rect", xmin = 30, xmax = 40, ymin = 0, ymax = Inf,
           alpha = 0.5, fill=K[7]) +
  stat_summary(fun.data=mean_sdl, geom="ribbon", 
               alpha=0.5, fill="grey50") +
  stat_summary(fun.y=mean, geom="line", lwd=2) +
  coord_cartesian(xlim=c(0,40), ylim=c(5,18)) +
  xlab("Frequency (Hz)") +
  theme_pander() +
  annotate("text", x=2, y=5, label="Delta", angle=90, hjust=0) +
  annotate("text", x=6, y=5, label="Theta", angle=90, hjust=0) +
  annotate("text", x=10.5, y=5, label="Alpha", angle=90, hjust=0) +
  annotate("text", x=14, y=5, label="Low Beta", angle=90, hjust=0) +
  annotate("text", x=16.5, y=5, label="Upper Beta", angle=90, hjust=0) +
  annotate("text", x=24, y=5, label="High Beta", angle=90, hjust=0) +
  annotate("text", x=35, y=5, label="Gamma", angle=90, hjust=0) 

```

# Correlations with Learning Rate

First, we calculate the mean power for every band and channel, and remove participants not inclided 

```{r}

wbehav <- wbehav %>%
  mutate(GlobalAlpha=(Vocabulary + Maps)/2)

Adata <- lspectra %>% group_by(Subject, Channel, Band) %>% summarize(Power=mean(Power))

Cdata <- group_by(Adata, Channel, Band) %>% 
  summarize(VocabR = cor(Power, wbehav$Vocabulary),
            MapsR = cor(Power, wbehav$Maps),
            GlobalR = cor(Power, wbehav$GlobalAlpha),
            VocabP = cor.test(Power, wbehav$Vocabulary)$p.value,
            MapsP = cor.test(Power, wbehav$Maps)$p.value,
            GlobalP = cor.test(Power, wbehav$GlobalAlpha)$p.value)

p1 <-ggplot(Cdata, aes(x=Channel, y=VocabR, col=Band)) +
  geom_point() +
  stat_summary(fun.data = "mean_se", col="black", alpha=0.5, geom = "errorbar") +
  ggtitle("Vocab, By Channel") +
  annotate("segment", x=-Inf, xend=Inf, y=0.28, yend = 0.28, lty=2) +
  annotate("segment", x=-Inf, xend=Inf, y=-0.28, yend = -0.28, lty=2) +

  theme_pander()

p2 <- ggplot(Cdata, aes(x=Band, y=VocabR, col=Channel)) +
  geom_point() +
  stat_summary(fun.data = "mean_se", col="black", alpha=0.5, geom = "errorbar") +
  ggtitle("Vocab, by Band") +
  annotate("segment", x=-Inf, xend=Inf, y=0.28, yend = 0.28, lty=2) +
  annotate("segment", x=-Inf, xend=Inf, y=-0.28, yend = -0.28, lty=2) +
  theme_pander()


p3 <-ggplot(Cdata, aes(x=Channel, y=GlobalR, col=Band)) +
  geom_point() +
  stat_summary(fun.data = "mean_se", col="black", alpha=0.5, geom = "errorbar") +
  ggtitle("Global, By Channel") +
  annotate("segment", x=-Inf, xend=Inf, y=0.28, yend = 0.28, lty=2) +
  annotate("segment", x=-Inf, xend=Inf, y=-0.28, yend = -0.28, lty=2) +

  theme_pander()

p4 <- ggplot(Cdata, aes(x=Band, y=GlobalP, col=Channel)) +
  geom_point() +
  stat_summary(fun.data = "mean_se", col="black", alpha=0.5, geom = "errorbar") +
  ggtitle("Global, by Band") +
  annotate("segment", x=-Inf, xend=Inf, y=0.28, yend = 0.28, lty=2) +
  annotate("segment", x=-Inf, xend=Inf, y=-0.28, yend = -0.28, lty=2) +
  annotate("segment", x=-Inf, xend=Inf, y=0.05, yend = 0.05, lty=2) +
  scale_y_log10() +
  theme_pander()
grid.arrange(p1, p2, p3, p4, ncol=2)
  
```



# Correlations from 

First, we need to load the summary files

```{r}
summary <- NULL
for (sub in dir()[grep("A[1-9]", dir())]) {
  table <- read_tsv(paste(sub, "/", sub, "_closed_summary.txt", sep=""),
                    col_types = cols())
  if (is.null(summary)) {
    summary <- table
  } else {
    summary <- summary %>% bind_rows(table)
  }
}

report <- wbehav %>% inner_join(summary, by=c("Subject"))
```

Confirming the correlation first obersevd by Peiyun.

```{r fig.width=5, fig.height=5}
p9 <- ggplot(report, aes(x=Vocabulary, y=P8_mean_Low.Beta_power)) +
  geom_point(size=4, alpha=0.5, col="black") +
  geom_smooth(method = "lm", formula = y ~ x, col="red", 
              fill="red", fullrange = T) +
  theme_pander() +
  ylab("Mean Low Beta Power at P8") +
  xlab(expression(paste(alpha, " Vocabulary"))) +
  scale_x_continuous() + 
  scale_y_continuous() + 
  coord_fixed(ratio = 13.333) + 
  coord_cartesian(xlim=c(0.1, 0.4), ylim=c(8, 12)) +
  #geom_rug(col="black", lwd=1, alpha=.5) +
  annotate("text", label = paste("R =", round(cor(report$Vocabulary,
                                                  report$P8_mean_Low.Beta_power),
                                              2)), 
                                 x=0.15, y=10.5, col="red") +
  ggtitle("Correlation Between\nForgetting Rate and EEG Power") +
  theme(plot.title = element_text(hjust = 0.5))

ggMarginal(p9, type="hist", col="white", 
           fill="black", alpha=0.5, bins=10)
```

# Dimensionality reduction

```{r}
# glspectra <- lspectra %>%
#   group_by(Channel, Frequency) %>%
#   summarize(Power=mean(Power)) %>%
#   filter(Frequency<= 40)
# 
# gl <- glspectra %>%
#   pivot_wider(#id_cols=(Frequency), 
#               names_from=Channel, 
#               values_from=Power) %>%
#   select(-Frequency)
# 
# 
# dm <- dist(1 - cor(gl)^2)
# clust <- hclust(dm)
# 
# ggdendrogram(clust)
# 
# # We have 3 clusters, let's select them
# 
# #K <- kmeans(dm, 4)$cluster
# 
# K <- cutree(clust, k=2)
# 
# lspectra <- lspectra %>%
#   mutate(Cluster = as.numeric(K[Channel]))
# 
# first.comp <- function(data) {
#   mdata <- data %>%
#     filter(Frequency <= 40) %>%
#     pivot_wider(names_from=Channel, 
#                        values_from=Power) %>%
#     select(one_of(names(K)))
#   
#   -1 * prcomp(mdata)$x[,1]
# }
# 
# lspectra <- lspectra %>%
#   mutate(Cluster = K[Channel])
# 
# # for (s in unique(lspectra$Subject)) {
# #   res <- NULL
# #   for (k in unique(lspectra$Cluster)) {
# #     sub <- lspectra %>%
# #       filter(Subject == s & Cluster == k)
# #     c1 <- first.comp(sub)
# #     t1 <- as_tibble(data.frame(Subject=s, Cluster=k, C1=c1, Frequency=seq(0.5, 40, 0.5)))
# #     if (is.null(res)) {
# #       res <- t1
# #     } else {
# #       res <- res %>% bind_rows(t1)
# #     }
# #   }
# #   res
# # }
# # 
# # res <- res 
# 
# res <- lspectra %>%
#   group_by(Subject, Frequency, Cluster) %>%
#   summarize_all(mean)
# 
# res <- res %>%
#   mutate(Band="Gamma")
# res$Band[res$Frequency <= 40] <- "Gamma"
# res$Band[res$Frequency < 30] <- "High Beta"
# res$Band[res$Frequency < 18] <- "Upper Beta"
# res$Band[res$Frequency < 15] <- "Low Beta"
# res$Band[res$Frequency < 13] <- "Alpha"
# res$Band[res$Frequency < 8] <- "Theta"
# res$Band[res$Frequency < 4] <- "Delta"
# 
# RAdata <- res %>% group_by(Subject, Cluster, Band) %>% summarize(Power=mean(C1))
# 
# RCdata <- group_by(RAdata, Cluster, Band) %>% 
#   summarize(VocabR = cor(Power, wbehav$Vocabulary),
#             MapsR = cor(Power, wbehav$Maps),
#             GlobalR = cor(Power, wbehav$GlobalAlpha),
#             VocabP = cor.test(Power, wbehav$Vocabulary)$p.value,
#             MapsP = cor.test(Power, wbehav$Maps)$p.value,
#             GlobalP = cor.test(Power, wbehav$GlobalAlpha)$p.value)
# 
# ggplot(RCdata, aes(x=Cluster, y=GlobalP, col=Band)) +
#   geom_point() +
#   stat_summary(fun.data = "mean_se", col="black", alpha=0.5, geom = "errorbar") +
#   ggtitle("Global, by Band") +
#   annotate("segment", x=-Inf, xend=Inf, y=0.28, yend = 0.28, lty=2) +
#   annotate("segment", x=-Inf, xend=Inf, y=-0.28, yend = -0.28, lty=2) +
#   annotate("segment", x=-Inf, xend=Inf, y=0.05, yend = 0.05, lty=2) +
#   scale_y_log10() +
#   theme_pander()

#pcas <- lspectra %>%
#  group_by(Subject, Cluster) %>%
#  summarize(Comp1 = first.comp())

```
